{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nData Management in Python Using Standard Tooling\n================================================\n\nPrior to beginning the tutorial, please install the following packages\nvia ``pip``: - pandas - matplotlib - statsmodels - seaborn - openpyxl -\nxlrd\n\n**Note**: if you're using Anaconda, some of these will be installed\nalready.\n\n**Note**: if you're running the example in Binder, no installation is\nnecessary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Overview\n--------\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``pandas`` is a large library which includes a data structure called a\n``DataFrame`` which is originally based on R's ``data.frame``. In\nPython, it is built on top of the array datatype in the similarly\npopular ``numpy`` library. Each column in a ``DataFrame`` is a\n``pandas Series``.\n\nI use ``numpy`` for some specific functions or when I need higher\nperformance than ``pandas``, but ``pandas`` is much more convenient to\nuse.\n\nHere is what we're going to cover:\n\n-  `**Selecting Data** <#Selecting-Data>`__\n-  `**Aggregating** <#Aggregating>`__\n-  `**Merging** <#Merging>`__\n-  `**Time series** <#Time-series>`__\n-  `**Plotting** <#Plotting>`__\n-  `**Regressions** <#Regressions>`__\n-  `**Input and Output** <#Input-and-Output>`__\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Give me a ``DataFrame``!\n------------------------\n\nA ``DataFrame`` can be created in many ways, including: - From a ``csv``\nor Excel file - From a ``SAS7BDAT`` (SAS data) or ``dta`` (Stata data)\nfile - From other Python data structures (list of tuples, dictionaries,\n``numpy`` arrays)\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here I will create an example ``DataFrame`` from a list of tuples. At\nthe end I will show loading and writing to files.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd #this is the convention for importing pandas, then you can use pd. for functions\n\ndf = pd.DataFrame(\n    data=[\n        ('Walmart', 'FL', '1/2/2000', .02),\n        ('Walmart', 'FL', '1/3/2000', .03),\n        ('Walmart', 'FL', '1/4/2000', .04),\n        ('Trader Joes', 'GA', '1/2/2000', .06),\n        ('Trader Joes', 'GA', '1/3/2000', .07),\n        ('Trader Joes', 'GA', '1/4/2000', .08),\n        ('Publix', 'FL', '1/2/2000', .1),\n        ('Publix', 'FL', '1/3/2000', .11),\n        ('Publix', 'FL', '1/4/2000', .12),\n    ], \n    columns = ['Company', 'State', 'Date', 'Return']\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``pandas`` combined with Jupyter gives you a nice representation of your\ndata by simply typing the name of the variable storing your\n``DataFrame``:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Working with Data in Pandas\n---------------------------\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One of the ``DataFrame``\\ s greatest strengths is how flexibly they can\nbe split, combined, and aggregated.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Selecting Data\n~~~~~~~~~~~~~~\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df[df['State'] == 'FL'] # read: dataframe where the dataframe column 'state' is 'FL'\n\ndf.iloc[1:3] # give me the second through the third rows\n\ndf.iloc[:, 2] # all rows for the third column (looks different because it's a Series)\n\ndf['Company'] # company column (Series)\n\nbest_grocery_stores = ['Trader Joes', 'Publix']\n# only rows where company is in the best grocery stores and has a high return,\n# but also give me only the company and return columns\ndf.loc[df['Company'].isin(best_grocery_stores) & (df['Return'] > 0.07), ['Company', 'Return']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aggregating\n~~~~~~~~~~~\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``DataFrame``\\ s have a ``.groupby`` which works similarly to group by\nin a SQL (proc SQL) command.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df.groupby('Company')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To make it useful, we must aggregate the data somehow:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df.groupby(['State','Date']).mean() #also .median, .std, .count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that there the index becomes the groupby columns. If we want keep\nthe columns in the ``DataFrame``, pass ``as_index=False``.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df.groupby(['State','Date'], as_index=False).mean() #also .median, .std, .count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that the shape of the data when using plain groupby is whatever the\nshape of the unique values of the groupby columns. If instead we want to\nadd a column to our ``DataFrame`` representing the aggregated values,\nuse ``.transform`` on top of ``groupby``.\n\nThis example also shows how to assign a new column to a ``DataFrame``.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df['State Return Average'] = df.groupby(['State','Date']).transform('mean')\ndf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Columns can be combined with basic math operations\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df['Ratio'] = df['Return'] / df['State Return Average']\ndf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Functions can be applied to columns or the entire ``DataFrame``:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np # convention for importing numpy.\n\ndef sort_ratios(value):\n\n    # If the value is missing or is not a number, return as is\n    # Without this, the function will error out as soon as it hits either of those\n    if pd.isnull(value) or not isinstance(value, np.float):\n        return value\n    \n    # Otherwise, sort into categories based on the value\n    if value == 1:\n        return 'Even'\n    if value < 1:\n        return 'Low'\n    if value >= 1:\n        return 'High'\n    \ndf['Ratio Size'] = df['Ratio'].apply(sort_ratios) # apply function to ratio column, save result as ratio size column\ndf\n\ndf.applymap(sort_ratios) # apply function to all values in df, but only display and don't save back to df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merging\n~~~~~~~\n\nSee here for more details.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's create a ``DataFrame`` containing information on employment rates\nin the various states and merge it to this dataset.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "employment_df = pd.DataFrame(\n    data=[\n        ('FL', 0.06),\n        ('GA', 0.08),\n        ('PA', 0.07)\n    ],\n    columns=['State', 'Unemployment']\n)\nemployment_df\n\ndf = df.merge(employment_df, how='left', on='State')\ndf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Appending is similarly simple. Here I will append a slightly modified\n``DataFrame`` to itself:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "copy_df = df.copy()\ncopy_df['Extra Column'] = 5\ncopy_df.drop('Ratio Size', axis=1, inplace=True) # inplace=True means it gets dropped in the existing DataFrame\ndf.append(copy_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can append to the side as well! (concatenate)\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "temp_df = pd.concat([df, copy_df], axis=1)\ntemp_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Be careful, ``pandas`` allows you to have multiple columns with the same\nname (generally a bad idea):\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "temp_df['Unemployment']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Time series\n~~~~~~~~~~~\n\nSee here for more details.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lagging\n^^^^^^^\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lags are easy with ``pandas``. The number in shift below represents the\nnumber of rows to lag.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df.sort_values(['Company', 'Date'], inplace=True)\ndf['Lag Return'] = df['Return'].shift(1)\ndf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But really we want the lagged value to come from the same firm:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df['Lag Return'] = df.groupby('Company')['Return'].shift(1)\ndf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Things get slightly more complicated if you want to take into account\nmissing dates within a firm. Then you must fill the ``DataFrame`` with\nmissing data for those excluded dates, then run the above function, then\ndrop those missing rows. A bit too much for this tutorial, but I have\ncode available for this upon request.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resampling\n^^^^^^^^^^\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``pandas`` has a lot of convenient methods for changing the frequency of\nthe data.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here I will create a df containing intraday returns for the three\ncompanies\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import datetime\nfrom itertools import product\n\nfirms = df['Company'].unique().tolist() # list of companies in df\ndates = df['Date'].unique().tolist() # list of dates in df\nnum_periods_per_day = 13 #30 minute intervals\ncombos = product(firms, dates, [i+1 for i in range(num_periods_per_day)]) # all combinations of company, date, and period number\ndata_tuples = [\n    (\n        combo[0], # company\n        datetime.datetime.strptime(combo[1], '%m/%d/%Y') + datetime.timedelta(hours=9.5, minutes=30 * combo[2]), #datetime\n        np.random.rand() * 100 # price\n    ) \n    for combo in combos\n]\nintraday_df = pd.DataFrame(data_tuples, columns=['Company', 'Datetime', 'Price'])\nintraday_df.head() # now the df is quite long, so we can use df.head() and df.tail() to see beginning and end of df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First must set the date variable as the index to do resampling\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "intraday_df.set_index('Datetime', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can resample to aggregate:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "intraday_df.groupby('Company').resample('1D').mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Or we can increase the frequency of the data, using ``bfill`` to\nbackward fill or ``ffill`` to forward fill. Here I specify to backward\nfill but only go back one period at most.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "intraday_df.groupby('Company').resample('10min').bfill(limit=1).head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting\n~~~~~~~~\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Oh yeah, we've got graphs too. ``pandas``' plotting functionality is\nbuilt on top of the popular ``matplotlib`` library, which is a graphing\nlibrary based on ``MATLAB``'s graphing functionality.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# we've got to run this magic once per session if we want graphics to show up in the notebook \n# %matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``pandas`` tries to guess what you want to plot. By default it will put\neach numeric column as a y variable and the index as the x variable.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But we can tell it specifically what we want to do. Maybe we want one\nplot for each company showing only how the company return moves relative\nto the state average return over time.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df\n\ndf['Date'] = pd.to_datetime(df['Date']) # convert date from string type to datetime type\ndf.groupby('Company').plot(y=['Return', 'State Return Average'], x='Date')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``pandas`` exposes most of the plots in ``matplotlib``. Supported types\ninclude: - \u2018line\u2019 : line plot (default) - \u2018bar\u2019 : vertical bar plot -\n\u2018barh\u2019 : horizontal bar plot - \u2018hist\u2019 : histogram - \u2018box\u2019 : boxplot -\n\u2018kde\u2019 : Kernel Density Estimation plot - \u2018density\u2019 : same as \u2018kde\u2019 -\n\u2018area\u2019 : area plot - \u2018pie\u2019 : pie plot - \u2018scatter\u2019 : scatter plot -\n\u2018hexbin\u2019 : hexbin plot\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df.drop('Ratio', axis=1).plot(kind='box', figsize=(15,8))\n\ndf.plot(y=['Return', 'Unemployment'], kind='kde')\n\nmarket_share_df = pd.DataFrame(\n    data=[\n        ('Trader Joes', .2),\n        ('Walmart', .5),\n        ('Publix', .3)\n    ],\n    columns=['Company', 'Market Share']\n).set_index('Company')\nmarket_share_df.plot(y='Market Share', kind='pie', figsize=(6,6))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check out the ``seaborn`` package for some cool high level plotting\ncapabilities.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import seaborn as sns # convention for importing seaborn\nsns.pairplot(df[['Company', 'Return', 'State Return Average']], hue='Company')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Regressions\n-----------\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alright, we've got some cleaned up data. Now we can run regressions on\nthem with the ``statsmodels`` module. Here I will show the \"formula\"\napproach to ``statsmodels``, which is just one of the two main\ninterfaces. The ``formula`` approach will feel similar to specifying a\nregression in ``R`` or ``Stata``. However we can also directly pass\n``DataFrames`` containing the y and x variables rather than specifying a\nformula.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df\n\nimport statsmodels.formula.api as smf # convention for importing statsmodels\n\nmodel = smf.ols(formula=\"Return ~ Unemployment\", data=df)\nresult = model.fit()\nresult.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looks like a regression summary should. We can also use fixed effects\nand interaction terms. Here showing fixed effects:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df.rename(columns={'Ratio Size': 'ratio_size'}, inplace=True) # statsmodels formula doesn't like spaces in column names\nmodel2 = smf.ols(formula=\"Return ~ Unemployment + C(ratio_size)\", data=df)\nresult2 = model2.fit()\nresult2.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now interaction terms\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# use * for interaction keeping individual variables, : for only interaction \nmodel3 = smf.ols(formula=\"Return ~ Unemployment*Ratio\", data=df) \nresult3 = model3.fit()\nresult3.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Want to throw together these models into one summary table?\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from statsmodels.iolib.summary2 import summary_col\n\nreg_list = [result, result2, result3]\nsumm = summary_col(\n    reg_list,\n    stars=True,\n    info_dict = {\n        'N': lambda x: \"{0:d}\".format(int(x.nobs)),\n        'Adj-R2': lambda x: \"{:.2f}\".format(x.rsquared_adj)\n    }\n)\nsumm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On the backend, ``statsmodels``' ``summary_col`` uses a ``DataFrame``\nwhich we can access as:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "summ.tables[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Therefore we can write functions to do any cleanup we want on the\nsummary, leveraging ``pandas``:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def replace_fixed_effects_cols(df):\n    \"\"\"\n    hackish way to do this just for example\n    \"\"\"\n    out_df = df.iloc[4:] #remove fixed effect dummy rows\n    out_df.loc['Ratio Size Fixed Effects'] = ('No', 'Yes', 'No')\n    return out_df\n\nclean_summ = replace_fixed_effects_cols(summ.tables[0])\nclean_summ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pretty cool, right? Since it's a ``DataFrame``, we can even output it to\nLaTeX:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "clean_summ.to_latex()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looks messy here, but you can output it to a file. However it's only\noutputting the direct LaTeX for the table so we can add a wrapper so it\nwill compile as document:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def _latex_text_wrapper(text):\n    begin_text = r\"\"\"\n    \\documentclass[12pt]{article}\n\\usepackage{booktabs}\n\\begin{document}\n\n\\begin{table}\n\n    \"\"\"\n    \n    end_text = r\"\"\"\n    \n    \\end{table}\n\\end{document}\n    \"\"\"\n    \n    return begin_text + text + end_text\n\ndef to_latex(df, filepath='temp.tex'):\n    latex = df.to_latex()\n    full_latex = _latex_text_wrapper(latex)\n    with open(filepath, 'w') as f:\n        f.write(full_latex)\n        \nto_latex(clean_summ) # created temp.tex in this folder. Go look and try to compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Input and Output\n----------------\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's output our existing ``DataFrame`` to some different formats and\nthen show it can be loaded in through those formats as well.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We are not using the index, so don't write it to file\ndf.to_csv('temp.csv', index=False)\ndf.to_excel('temp.xlsx', index=False)\ndf.to_stata('temp.dta', write_index=False)\n# NOTE: it is possible to read from SAS7BDAT but not write to it\n\npd.read_csv('temp.csv')\n\npd.read_excel('temp.xlsx')\n\npd.read_stata('temp.dta')\n\n# pd.read_sas('temp.sas7bdat') #doesn't exist because we couldn't write to it. But if you already have sas data this will work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Some Clean Up\n-------------\n\nThis section is not important, just cleaning up the temporary files we\njust generated.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n\nclean_files = [\n    'temp.csv',\n    'temp.xlsx',\n    'temp.dta',\n    'temp.tex',\n]\n\nfor file in clean_files:\n    os.remove(file)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}